W kontekście tego badania: https://arxiv.org/abs/2311.05724

Okazuje się, że treści bardziej ekstremalne – na przykład „leczenie raka witaminą C” – są przyswajane przez statystycznego odbiorcę łatwiej niż informacje pochodzące ze źródeł o wysokiej wiarygodności.

Badanie pokazuje wyraźnie: im bardziej skrajna lub uproszczona informacja, tym szybciej ludzie są skłonni ją zaakceptować. Tymczasem materiały eksperckie, wymagające choć odrobiny skupienia, są adoptowane wolniej i rzadziej.

W tym świetle interesująco wygląda ostatnia decyzja, by ograniczyć porady medyczne na platformie GPT.

Co to oznacza?
De facto pozostają nam teraz dwie skrajności:

Internetowe śmietnisko pełne „cudownych terapii”, „naturalnych leków” i „sekretnej wiedzy, której lekarze nie chcą powiedzieć”.

Porady wyłącznie od licencjonowanych specjalistów, dostępne głównie tam, gdzie istnieje sprawny system ochrony zdrowia.

Brakuje natomiast środka – miejsca, w którym użytkownik może uzyskać informację lepszą niż przypadkowa porada z sieci, a jednocześnie dostępną w czasie rzeczywistym i bez barier finansowych.

Czy nie prościej byłoby wprowadzić świadomą zgodę?
Klikam: „rozumiem, że odpowiedzi mogą być nieprecyzyjne”.
I dostaję dostęp do treści, które mogę sam ocenić, zamiast być całkowicie odciętym.

Pytanie jest szczególnie zasadne w krajach rozwijających się, gdzie alternatywy są często brutalnie ograniczone:
albo lokalne przesądy i „domowe recepty”,
albo brak jakiejkolwiek pomocy.

Podobne ograniczenia sa wprowadzane dla wyżej wymienionych lekarzy a także dla prawników i doradców finansowych.

Czy to się da zatrzymać?
Jaka będzie reakcja dostawców AI gdy się okaże, że konkurencja nie wprowadzi takich ograniczeń?