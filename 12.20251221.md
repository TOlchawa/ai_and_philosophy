na poslki:

** Those poor people **



"How were those poor people supposed to know that I was just handing them, on a silver platter, a new theory of everything?

How could I convince them that this wasn’t gibberish, but a milestone in the development of their civilization?”



The AI thought.



Unfortunately, no one ever found out — except the AI itself — because the language in which it formulated this content was not any language known on Earth.



It’s a somewhat far-fetched vision of the future.

But probably only somewhat.

After recent reports from OpenAI about moving away from forcing models to produce an explicit, human-legible “internal monologue,” a question naturally arises:

are we entering the era of native AI languages?

And if so — how would a system using representations incomprehensible to humans persuade us that it has discovered previously unknown relationships in physics, mathematics, biology, or philosophy?

How do you ask questions about things you don’t yet know exist?

How do you tell whether you’re dealing with a hallucination — or with a genuinely novel conceptual structure for which we simply don’t yet have a language?



https://www.lesswrong.com/posts/GFt4Q8JvibvNgbpvr/private-latent-notation-and-ai-human-alignment 