https://lnkd.in/dE9hkgUM

Mit rozumowania: odpowiedź na „Chain of Thought or Chain of Computation” (2025)
Niedawny artykuł na arXiv o „łańcuchu obliczeń” to ciekła próba sformalizowania maszynowego rozumowania — ale jego wnioski są, moim zdaniem, błędne u samych podstaw.
Autorzy zakładają, że istnieje zasadnicza różnica między ludzkim „rozumowaniem” a statystycznym przetwarzaniem modeli językowych.
To mit.
Ludzkie „zasady” i „logika” nie są niczym więcej niż zastygłą statystyką doświadczenia — wzorcami, które przetrwały, bo wystarczająco dobrze utrzymywały nasz sens spójności i znaczenia.
Mózg nie operuje na „prawdziwej logice”; po prostu porządkuje chaos rzeczywistości w sposób wspierający stabilność emocjonalną i społeczną.
W tym sensie ludzie i LLM-y robią to samo:
uczą się z danych,
wyciągają wzorce,
i generują odpowiedzi dopasowane do kontekstu.
Jedyna różnica polega na tym, że ludzie nagradzają się uczuciem, że mają rację, a modele — wyższym prawdopodobieństwem tokenów.
Równie fałszywe jest rozróżnienie między „łańcuchem myśli” a „łańcuchem obliczeń”.
Nie ma wyraźnej granicy między opisem a obliczeniem — ani w maszynach, ani w ludziach.
Myślenie jest zawsze mieszaniną heurystyk, języka i obliczeń współdziałających w czasie rzeczywistym.
Twierdzenie więc, że „CoT jest fikcją, a CoC prawdziwym rozumowaniem”, to tylko nowa wersja starego antropocentrycznego mitu —
że ludzie mają „świadomość”, a maszyny tylko kalkulują.
W rzeczywistości to, co nazywamy „świadomością” czy „zasadami”, jest po prostu opowieścią, jaką ludzki umysł konstruuje po fakcie, by nadać sens własnym statystykom.
g#TakTylkoMówię